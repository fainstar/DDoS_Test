import torch
import time

def check_torch_gpu():
    print("ğŸ” PyTorch æª¢æ¸¬å ±å‘Šï¼š")

    if torch.cuda.is_available():
        print("âœ… CUDA å¯ç”¨ï¼")
        print(f"ğŸ“Ÿ GPU åç¨±ï¼š{torch.cuda.get_device_name(0)}")
        print(f"ğŸ’¾ GPU è¨˜æ†¶é«”ç¸½é‡ï¼š{round(torch.cuda.get_device_properties(0).total_memory / (1024**3), 2)} GB")
        print(f"ğŸ”¥ GPU æ•¸é‡ï¼š{torch.cuda.device_count()}")

        # Tensor é‹ç®—æ¸¬è©¦
        a = torch.rand(10000, 10000, device="cuda")
        b = torch.rand(10000, 10000, device="cuda")
        torch.cuda.synchronize()
        start = time.time()
        c = torch.matmul(a, b)
        torch.cuda.synchronize()
        end = time.time()
        print(f"âš™ï¸ GPU é‹ç®—æ™‚é–“ï¼š{end - start:.4f} ç§’")

        # PYNVML ç‹€æ…‹æª¢æŸ¥
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)
            print(f"ğŸ“Š GPU ä½¿ç”¨è¨˜æ†¶é«”ï¼š{round(mem_info.used / (1024**3), 2)} / {round(mem_info.total / (1024**3), 2)} GB")
            print(f"ğŸ”‹ GPU æº«åº¦ï¼š{pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)} Â°C")
            pynvml.nvmlShutdown()
        except Exception as e:
            print(f"âŒ pynvml éŒ¯èª¤ï¼š{e}")
    else:
        print("âŒ æ²’æœ‰åµæ¸¬åˆ°å¯ç”¨çš„ GPUï¼Œå¿«å»è£é¡¯å¡æˆ–æª¢æŸ¥ CUDA ç’°å¢ƒï¼ğŸ¥²")

check_torch_gpu()

import pandas as pd
with open('final_dataset.csv', 'r', encoding='utf-8') as f:
    head = [next(f) for _ in range(5)]
print(''.join(head))